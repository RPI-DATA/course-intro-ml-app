{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_intro_api_twitter.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/04-viz-api-scraper/01_intro_api_twitter.ipynb","timestamp":1548900753768}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"M8k48eZMpi9U","colab_type":"text"},"cell_type":"markdown","source":["\n","[![AnalyticsDojo](https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/fig/final-logo.png?raw=1)](http://rpi.analyticsdojo.com)\n","<center><h1>Introduction to API's with Python</h1></center>\n","<center><h3><a href = 'http://rpi.analyticsdojo.com'>rpi.analyticsdojo.com</a></h3></center>\n"]},{"metadata":{"id":"dUJnFCHgpi9b","colab_type":"text"},"cell_type":"markdown","source":["\n","This is adopted from [Mining the Social Web, 2nd Edition](http://bit.ly/16kGNyb)\n","Copyright (c) 2013, Matthew A. Russell\n","All rights reserved.\n","\n","This work is licensed under the [Simplified BSD License](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/LICENSE.txt)."]},{"metadata":{"id":"BbhBJEttpi9f","colab_type":"text"},"cell_type":"markdown","source":["### Before you Begin #1\n","If you are working locally or on colab, this exercise requires the twitter package and the ruamel.yaml package.   Yaml files are structured files useful for storing configuration. \n"]},{"metadata":{"id":"ayOChWv3pi9k","colab_type":"code","colab":{}},"cell_type":"code","source":[" !pip install twitter ruamel.yaml"],"execution_count":0,"outputs":[]},{"metadata":{"id":"REhWPaFqpi9y","colab_type":"code","colab":{}},"cell_type":"code","source":["#see if it worked by importing the twitter package & some other things we will use.  \n","from  twitter import *\n","import datetime, traceback \n","import json\n","import time\n","import sys\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZceZWICCpi9_","colab_type":"text"},"cell_type":"markdown","source":["### Before you Begin #2\n","Download the sample configuration.  \n"]},{"metadata":{"id":"-_lUk3c4pi-D","colab_type":"code","colab":{}},"cell_type":"code","source":["!!wget https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/04-viz-api-scraper/screen_names.csv && wget https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/04-viz-api-scraper/twitlab.py \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j3zwhJU30ubs","colab_type":"text"},"cell_type":"markdown","source":["# Download Authorization file (look at Slack for file)"]},{"metadata":{"id":"BXBkHKYR0tKt","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget https://www.dropbox.com/s/ojjs2aj14gjuqjb/config.yaml "],"execution_count":0,"outputs":[]},{"metadata":{"id":"estmos5Mpi-K","colab_type":"text"},"cell_type":"markdown","source":["## Step1.  Loading Authorization Data\n","- Here we are going to store the authorization data in a .YAML file rather than directly in the notebook.  \n","- We have also added `config.yaml` to the `.gitignore` file so we won't accidentally commit our sensitive data to the repository.\n","- You should generally keep sensitive data out of all git repositories (public or private) but definitely Public. \n","- If you ever accidentally commit data to a public repository you must consider it compromised.\n","- A .yaml file is a common way to store configuration data, but it is not really secure. "]},{"metadata":{"id":"3bMB-8t5pi-O","colab_type":"code","colab":{}},"cell_type":"code","source":["#This will import some required libraries.\n","import sys \n","import ruamel.yaml #A .yaml file \n","#This is your configuration file. \n","twitter_yaml='config.yaml'\n","with open(twitter_yaml, 'r') as yaml_t:\n","    cf_t=ruamel.yaml.round_trip_load(yaml_t, preserve_quotes=True)\n","\n","#You can check your config was loaded by printing, but you should not commit this.\n","cf_t\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4oceJAex3dZh","colab_type":"text"},"cell_type":"markdown","source":["# `cat` command to look at files\n","We can use the `cat` command to look at the structure of our files. "]},{"metadata":{"id":"qL5lShkF3XPf","colab_type":"code","colab":{}},"cell_type":"code","source":["!cat config.yaml"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-on6IWMIpi-i","colab_type":"text"},"cell_type":"markdown","source":["## Create Some Relevant Functions\n","- We first will create a Twitter object we can used to authorize data.\n","- Then we will get profiles.\n","- Finally we will get some tweets.  \n","\n","**Don't worry about not understanding all the code.  Here we are pushing you us more complex functions.**"]},{"metadata":{"id":"QCilB6v2pi-l","colab_type":"code","colab":{},"cellView":"both"},"cell_type":"code","source":["#@title\n","def create_twitter_auth(cf_t):\n","        \"\"\"Function to create a twitter object\n","           Args: cf_t is configuration dictionary. \n","           Returns: Twitter object.\n","            \"\"\"\n","        # When using twitter stream you must authorize.\n","        # these tokens are necessary for user authentication\n","        # create twitter API object\n","\n","        auth = OAuth(cf_t['access_token'], cf_t['access_token_secret'], cf_t['consumer_key'], cf_t['consumer_secret'])\n","\n","        try:\n","            # create twitter API object\n","            twitter = Twitter(auth = auth)\n","        except TwitterHTTPError:\n","            traceback.print_exc()\n","            time.sleep(cf_t['sleep_interval'])\n","        return twitter"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vU-Kd1tspi-q","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_profiles(twitter, names, cf_t):\n","    \"\"\"Function write profiles to a file with the form *data-user-profiles.json*\n","       Args: names is a list of names\n","             cf_t is a list of twitter config\n","       Returns: Nothing\n","        \"\"\"\n","    # file name for daily tracking\n","    dt = datetime.datetime.now()\n","    fn = cf_t['data']+'/profiles/'+dt.strftime('%Y-%m-%d-user-profiles.json')\n","    with open(fn, 'w') as f:\n","        for name in names:\n","            print(\"Searching twitter for User profile: \", name)\n","            try:\n","                # create a subquery, looking up information about these users\n","                # twitter API docs: https://dev.twitter.com/docs/api/1/get/users/lookup\n","                profiles = twitter.users.lookup(screen_name = name)\n","                sub_start_time = time.time()\n","                for profile in profiles:\n","                    print(\"User found. Total tweets:\", profile['statuses_count'])\n","                    # now save user info\n","                    f.write(json.dumps(profile))\n","                    f.write(\"\\n\")\n","                sub_elapsed_time = time.time() - sub_start_time;\n","                if sub_elapsed_time < cf_t['sleep_interval']:\n","                    time.sleep(cf_t['sleep_interval'] + 1 - sub_elapsed_time)\n","            except TwitterHTTPError:\n","                traceback.print_exc()\n","                time.sleep(cf_t['sleep_interval'])\n","                continue\n","    f.close()\n","    return fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NOnfoSR9pi-u","colab_type":"text"},"cell_type":"markdown","source":["## Load Twitter Handle From CSV\n","- This is a .csv that has individuals we want to collect data on. \n","- Go ahead and follow [AnalyticsDojo](https://twitter.com/AnalyticsDojo).  "]},{"metadata":{"id":"m_i5FAM7pi-w","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","df=pd.read_csv(cf_t['file'])\n","df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ADSz7EZkpi-4","colab_type":"text"},"cell_type":"markdown","source":["## Create Twitter Object"]},{"metadata":{"id":"bNn1Tz_opi-5","colab_type":"code","colab":{}},"cell_type":"code","source":["import twitlab"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jLCac_eVpi-8","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create Twitter Object\n","twitter= twitlab.create_twitter_auth(cf_t)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7zziUiqxpi-_","colab_type":"code","colab":{}},"cell_type":"code","source":["df['screen_name']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SFeVvoXVs53X","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir data && mkdir data/profiles"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IJwSKIx9pi_E","colab_type":"code","colab":{}},"cell_type":"code","source":["#This will get general profile data\n","profiles_fn=twitlab.get_profiles(twitter, df['screen_name'], cf_t)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QHNBC4q60GWl","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls data/profiles"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3jGqvyvv0XCi","colab_type":"text"},"cell_type":"markdown","source":["# Let's look at the files created.  "]},{"metadata":{"id":"d9lLNt0C0OPq","colab_type":"code","colab":{}},"cell_type":"code","source":["!cat data/profiles/*-user-profiles.json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MyHHXw6kpi_K","colab_type":"text"},"cell_type":"markdown","source":["The outcoming of running the above API is to generate a twitter object. "]},{"metadata":{"id":"k5K_tqPSpi_L","colab_type":"text"},"cell_type":"markdown","source":["## Step 2. Getting Help"]},{"metadata":{"id":"7EZWDoSupi_M","colab_type":"code","colab":{}},"cell_type":"code","source":["# We can get some help on how to use the twitter api with the following. \n","help(twitter)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K__yJC7ypi_R","colab_type":"text"},"cell_type":"markdown","source":["\n","Go ahead and take a look at the [twitter docs](https://dev.twitter.com/rest/public).\n","\n"]},{"metadata":{"id":"O0q3i561pi_T","colab_type":"code","colab":{}},"cell_type":"code","source":["# The Yahoo! Where On Earth ID for the entire world is 1.\n","# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n","# http://developer.yahoo.com/geo/geoplanet/\n","\n","WORLD_WOE_ID = 1\n","US_WOE_ID = 23424977\n","\n","# Prefix ID with the underscore for query string parameterization.\n","# Without the underscore, the twitter package appends the ID value\n","# to the URL itself as a special case keyword argument.\n","\n","world_trends = twitter.trends.place(_id=WORLD_WOE_ID)\n","us_trends = twitter.trends.place(_id=US_WOE_ID)\n","\n","print (world_trends)\n","print (us_trends)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tMS9yeDmpi_X","colab_type":"text"},"cell_type":"markdown","source":["## Step 3. Displaying API responses as pretty-printed JSON"]},{"metadata":{"id":"UPEUz449pi_Y","colab_type":"code","colab":{}},"cell_type":"code","source":["import json\n","\n","print (json.dumps(world_trends, indent=1))\n","print (json.dumps(us_trends, indent=1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OdNafaVvpi_d","colab_type":"text"},"cell_type":"markdown","source":["Take a look at the [api docs](https://dev.twitter.com/rest/reference/get/trends/place) for the /trends/place call made above. "]},{"metadata":{"id":"XAUYigJ2pi_f","colab_type":"text"},"cell_type":"markdown","source":["## Step 4. Collecting search results for a targeted hashtag."]},{"metadata":{"id":"o8ZnjmSDpi_g","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import unquote to prevent url encoding errors in next_results\n","#from urllib3 import unquote\n","\n","#This can be any trending topic, but let's focus on a hashtag that is relevant to the class. \n","q = '#analytics' \n","\n","count = 100\n","\n","# See https://dev.twitter.com/rest/reference/get/search/tweets\n","search_results = twitter.search.tweets(q=q, count=count)\n","\n","#This selects out \n","statuses = search_results['statuses']\n","\n","\n","# Iterate through 5 more batches of results by following the cursor\n","for _ in range(5):\n","    print (\"Length of statuses\", len(statuses))\n","    try:\n","        next_results = search_results['search_metadata']['next_results']\n","        print (\"next_results\", next_results)\n","    except: # No more results when next_results doesn't exist\n","        break\n","        \n","    # Create a dictionary from next_results, which has the following form:\n","    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n","    kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n","    print (kwargs)\n","    search_results = twitter.search.tweets(**kwargs)\n","    statuses += search_results['statuses']\n","\n","# Show one sample search result by slicing the list...\n","print (json.dumps(statuses[0], indent=1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"abp_tNyTpi_k","colab_type":"code","colab":{}},"cell_type":"code","source":["#Print several\n","print (json.dumps(statuses[0:5], indent=1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qqzT1NZ_pi_o","colab_type":"text"},"cell_type":"markdown","source":["## Step 5. Extracting text, screen names, and hashtags from tweets"]},{"metadata":{"id":"4AMge7Gapi_p","colab_type":"code","colab":{}},"cell_type":"code","source":["#We can access an individual tweet like so:\n","statuses[1]['text']\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MO9VaXeLpi_t","colab_type":"code","colab":{}},"cell_type":"code","source":["statuses[1]['entities']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7eplBeAMpi_x","colab_type":"code","colab":{}},"cell_type":"code","source":["#notice the nested relationships.  We have to take notice of this to further access the data.\n","statuses[1]['entities']['hashtags']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W8GRVU9Mpi_5","colab_type":"code","colab":{}},"cell_type":"code","source":["status_texts = [ status['text'] \n","                 for status in statuses ]\n","\n","screen_names = [ user_mention['screen_name'] \n","                 for status in statuses\n","                     for user_mention in status['entities']['user_mentions'] ]\n","\n","hashtags = [ hashtag['text'] \n","             for status in statuses\n","                 for hashtag in status['entities']['hashtags'] ]\n","\n","urls = [ url['url'] \n","             for status in statuses\n","                 for url in status['entities']['urls'] ]\n","\n","\n","\n","# Compute a collection of all words from all tweets\n","words = [ w \n","          for t in status_texts \n","              for w in t.split() ]\n","\n","# Explore the first 5 items for each...\n","\n","print (json.dumps(status_texts[0:5], indent=1))\n","print (json.dumps(screen_names[0:5], indent=1)) \n","print (json.dumps(hashtags[0:5], indent=1))\n","print (json.dumps(words[0:5], indent=1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CnGE1Erxpi_8","colab_type":"text"},"cell_type":"markdown","source":["## Step 6. Creating a basic frequency distribution from the words in tweets"]},{"metadata":{"id":"wcm2YTAhpi_-","colab_type":"code","colab":{}},"cell_type":"code","source":["from collections import Counter\n","\n","for item in [words, screen_names, hashtags]:\n","    c = Counter(item)\n","    print (c.most_common()[:10]) # top 10, \"\\n\")\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Thxemm3pjAA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}