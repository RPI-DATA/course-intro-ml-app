{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks \n",
    "- This was adopted from the PyTorch Tutorials. \n",
    "- http://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks \n",
    "- Neural networks are the foundation of deep learning, which has revolutionized the \n",
    "\n",
    "```In the mathematical theory of artificial neural networks, the universal approximation theorem states[1] that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of Rn, under mild assumptions on the activation function.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Fake Data\n",
    "- `D_in` is the number of dimensions of an input varaible.\n",
    "- `D_out` is the number of dimentions of an output variable.\n",
    "- Here we are learning some special \"fake\" data that represents the xor problem. \n",
    "- Here, the dv is 1 if either the first or second variable is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:\n",
      " [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]] \n",
      " Output data:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "#This is our independent and dependent variables. \n",
    "x = np.array([ [0,0,0],[1,0,0],[0,1,0],[0,0,0] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "print(\"Input data:\\n\",x,\"\\n Output data:\\n\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Neural Network \n",
    "- Here we are going to build a neural network with 2 hidden layers. \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=83832)\n",
    "#D_in is the number of input variables. \n",
    "#H is the hidden dimension.\n",
    "#D_out is the number of dimensions for the output. \n",
    "D_in, H, D_out = 3, 2, 1\n",
    "\n",
    "# Randomly initialize weights og out 2 hidden layer network.\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "bias = np.random.randn(H, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Appropriate Weights via Backpropogation\n",
    "- Learning rate adjust how quickly the model will adjust parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.6579261591\n",
      "1 9.10203339893\n",
      "2 7.92822558061\n",
      "3 7.01603070961\n",
      "4 6.28979819918\n",
      "5 5.69984738569\n",
      "6 5.21233053023\n",
      "7 4.80346624793\n",
      "8 4.456102755\n",
      "9 4.15758768903\n",
      "10 3.89840273398\n",
      "11 3.67126267684\n",
      "12 3.47050562961\n",
      "13 3.29167096682\n",
      "14 3.13120131373\n",
      "15 2.98622833978\n",
      "16 2.8544162991\n",
      "17 2.73384607859\n",
      "18 2.62292812419\n",
      "19 2.52033626007\n",
      "20 2.42495682843\n",
      "21 2.33584920317\n",
      "22 2.25221484357\n",
      "23 2.17337282724\n",
      "24 2.09874034592\n",
      "25 2.02781703626\n",
      "26 1.96017229769\n",
      "27 1.89543495408\n",
      "28 1.83328476643\n",
      "29 1.77344541638\n",
      "30 1.71567866423\n",
      "31 1.65977944954\n",
      "32 1.60557175094\n",
      "33 1.55290505986\n",
      "34 1.50165135204\n",
      "35 1.45170246386\n",
      "36 1.40296779892\n",
      "37 1.35537230457\n",
      "38 1.3088546702\n",
      "39 1.26336570846\n",
      "40 1.21886688836\n",
      "41 1.17532899574\n",
      "42 1.13273090181\n",
      "43 1.09105842491\n",
      "44 1.05030327423\n",
      "45 1.01046206727\n",
      "46 0.971535415306\n",
      "47 0.933527072858\n",
      "48 0.896443149097\n",
      "49 0.860291379845\n",
      "50 0.825080459944\n",
      "51 0.790819436113\n",
      "52 0.757517160723\n",
      "53 0.725181806896\n",
      "54 0.693820445158\n",
      "55 0.663438681518\n",
      "56 0.634040356373\n",
      "57 0.605627303094\n",
      "58 0.578199164525\n",
      "59 0.551753265011\n",
      "60 0.526284534957\n",
      "61 0.501785484373\n",
      "62 0.478246221337\n",
      "63 0.455654510907\n",
      "64 0.433995869718\n",
      "65 0.413253691241\n",
      "66 0.393409396657\n",
      "67 0.374442606233\n",
      "68 0.356331326268\n",
      "69 0.339052146831\n",
      "70 0.322580445843\n",
      "71 0.30689059538\n",
      "72 0.291956166492\n",
      "73 0.27775012929\n",
      "74 0.264245045477\n",
      "75 0.251413251035\n",
      "76 0.239227027168\n",
      "77 0.227658758121\n",
      "78 0.216681074855\n",
      "79 0.206266984003\n",
      "80 0.196389981824\n",
      "81 0.18702415323\n",
      "82 0.178144256176\n",
      "83 0.169725791964\n",
      "84 0.161745062156\n",
      "85 0.154179212936\n",
      "86 0.147006267869\n",
      "87 0.14020515004\n",
      "88 0.133755694633\n",
      "89 0.12763865297\n",
      "90 0.121835689045\n",
      "91 0.116329369558\n",
      "92 0.111103148388\n",
      "93 0.106141346409\n",
      "94 0.101429127469\n",
      "95 0.0969524713096\n",
      "96 0.0926981441057\n",
      "97 0.0886536672482\n",
      "98 0.0848072849255\n",
      "99 0.0811479309802\n",
      "100 0.0776651954621\n",
      "101 0.0743492912332\n",
      "102 0.0711910209273\n",
      "103 0.0681817445139\n",
      "104 0.0653133476691\n",
      "105 0.0625782111165\n",
      "106 0.0599691810633\n",
      "107 0.0574795408223\n",
      "108 0.0551029836872\n",
      "109 0.0528335870985\n",
      "110 0.0506657881215\n",
      "111 0.0485943602377\n",
      "112 0.0466143914385\n",
      "113 0.0447212635969\n",
      "114 0.042910633084\n",
      "115 0.0411784125909\n",
      "116 0.0395207541101\n",
      "117 0.0379340330255\n",
      "118 0.0364148332613\n",
      "119 0.0349599334326\n",
      "120 0.0335662939467\n",
      "121 0.0322310449976\n",
      "122 0.0309514754026\n",
      "123 0.0297250222266\n",
      "124 0.0285492611449\n",
      "125 0.0274218974944\n",
      "126 0.0263407579669\n",
      "127 0.0253037828991\n",
      "128 0.0243090191189\n",
      "129 0.0233546133048\n",
      "130 0.0224388058244\n",
      "131 0.0215599250132\n",
      "132 0.020716381864\n",
      "133 0.0199066650928\n",
      "134 0.0191293365551\n",
      "135 0.0183830269842\n",
      "136 0.0176664320279\n",
      "137 0.0169783085599\n",
      "138 0.0163174712444\n",
      "139 0.015682789336\n",
      "140 0.0150731836941\n",
      "141 0.0144876239984\n",
      "142 0.0139251261468\n",
      "143 0.0133847498242\n",
      "144 0.0128655962277\n",
      "145 0.0123668059377\n",
      "146 0.0118875569212\n",
      "147 0.0114270626611\n",
      "148 0.0109845703988\n",
      "149 0.0105593594834\n",
      "150 0.0101507398196\n",
      "151 0.00975805040627\n",
      "152 0.00938065796027\n",
      "153 0.00901795561851\n",
      "154 0.00866936171332\n",
      "155 0.00833431861585\n",
      "156 0.00801229164266\n",
      "157 0.00770276802156\n",
      "158 0.00740525591235\n",
      "159 0.00711928347915\n",
      "160 0.00684439801074\n",
      "161 0.0065801650859\n",
      "162 0.00632616778098\n",
      "163 0.00608200591689\n",
      "164 0.0058472953433\n",
      "165 0.00562166725752\n",
      "166 0.00540476755634\n",
      "167 0.00519625621854\n",
      "168 0.00499580671658\n",
      "169 0.0048031054556\n",
      "170 0.00461785123834\n",
      "171 0.00443975475448\n",
      "172 0.00426853809302\n",
      "173 0.00410393427663\n",
      "174 0.00394568681655\n",
      "175 0.00379354928727\n",
      "176 0.0036472849197\n",
      "177 0.00350666621201\n",
      "178 0.00337147455735\n",
      "179 0.00324149988737\n",
      "180 0.00311654033101\n",
      "181 0.00299640188771\n",
      "182 0.00288089811428\n",
      "183 0.00276984982498\n",
      "184 0.00266308480403\n",
      "185 0.00256043752998\n",
      "186 0.00246174891152\n",
      "187 0.00236686603409\n",
      "188 0.00227564191686\n",
      "189 0.0021879352796\n",
      "190 0.002103610319\n",
      "191 0.00202253649407\n",
      "192 0.00194458832016\n",
      "193 0.00186964517126\n",
      "194 0.00179759109024\n",
      "195 0.00172831460666\n",
      "196 0.00166170856184\n",
      "197 0.00159766994094\n",
      "198 0.00153609971162\n",
      "199 0.00147690266916\n",
      "200 0.00141998728767\n",
      "201 0.00136526557721\n",
      "202 0.00131265294649\n",
      "203 0.00126206807099\n",
      "204 0.0012134327663\n",
      "205 0.00116667186639\n",
      "206 0.00112171310662\n",
      "207 0.00107848701142\n",
      "208 0.00103692678629\n",
      "209 0.000996968213999\n",
      "210 0.000958549554938\n",
      "211 0.000921611451238\n",
      "212 0.000886096834699\n",
      "213 0.000851950838274\n",
      "214 0.000819120710998\n",
      "215 0.000787555736234\n",
      "216 0.000757207153079\n",
      "217 0.00072802808083\n",
      "218 0.000699973446382\n",
      "219 0.000672999914438\n",
      "220 0.00064706582042\n",
      "221 0.00062213110599\n",
      "222 0.000598157257058\n",
      "223 0.000575107244193\n",
      "224 0.000552945465343\n",
      "225 0.000531637690769\n",
      "226 0.000511151010104\n",
      "227 0.000491453781468\n",
      "228 0.000472515582542\n",
      "229 0.000454307163537\n",
      "230 0.000436800401976\n",
      "231 0.000419968259228\n",
      "232 0.000403784738718\n",
      "233 0.000388224845747\n",
      "234 0.000373264548871\n",
      "235 0.000358880742763\n",
      "236 0.000345051212511\n",
      "237 0.000331754599299\n",
      "238 0.000318970367402\n",
      "239 0.000306678772464\n",
      "240 0.000294860830993\n",
      "241 0.000283498291035\n",
      "242 0.000272573603982\n",
      "243 0.000262069897459\n",
      "244 0.000251970949269\n",
      "245 0.000242261162331\n",
      "246 0.000232925540587\n",
      "247 0.000223949665846\n",
      "248 0.00021531967551\n",
      "249 0.000207022241164\n",
      "250 0.000199044547992\n",
      "251 0.000191374274982\n",
      "252 0.000183999575901\n",
      "253 0.000176909060996\n",
      "254 0.000170091779404\n",
      "255 0.000163537202244\n",
      "256 0.000157235206347\n",
      "257 0.000151176058633\n",
      "258 0.000145350401071\n",
      "259 0.00013974923623\n",
      "260 0.000134363913387\n",
      "261 0.00012918611516\n",
      "262 0.000124207844669\n",
      "263 0.000119421413185\n",
      "264 0.000114819428254\n",
      "265 0.000110394782283\n",
      "266 0.000106140641559\n",
      "267 0.000102050435703\n",
      "268 9.8117847515e-05\n",
      "269 9.43368032245e-05\n",
      "270 9.07014631064e-05\n",
      "271 8.72062124641e-05\n",
      "272 8.38456529584e-05\n",
      "273 8.06145942704e-05\n",
      "274 7.7508046086e-05\n",
      "275 7.45212103889e-05\n",
      "276 7.16494740506e-05\n",
      "277 6.88884017067e-05\n",
      "278 6.62337289065e-05\n",
      "279 6.36813555272e-05\n",
      "280 6.12273394421e-05\n",
      "281 5.88678904323e-05\n",
      "282 5.6599364333e-05\n",
      "283 5.44182574058e-05\n",
      "284 5.23212009275e-05\n",
      "285 5.03049559874e-05\n",
      "286 4.83664084854e-05\n",
      "287 4.6502564322e-05\n",
      "288 4.47105447751e-05\n",
      "289 4.29875820531e-05\n",
      "290 4.13310150213e-05\n",
      "291 3.97382850912e-05\n",
      "292 3.82069322694e-05\n",
      "293 3.67345913581e-05\n",
      "294 3.53189883027e-05\n",
      "295 3.3957936679e-05\n",
      "296 3.26493343169e-05\n",
      "297 3.13911600538e-05\n",
      "298 3.01814706126e-05\n",
      "299 2.90183976007e-05\n",
      "300 2.79001446246e-05\n",
      "301 2.68249845149e-05\n",
      "302 2.57912566593e-05\n",
      "303 2.47973644376e-05\n",
      "304 2.38417727559e-05\n",
      "305 2.29230056755e-05\n",
      "306 2.20396441336e-05\n",
      "307 2.11903237516e-05\n",
      "308 2.03737327276e-05\n",
      "309 1.95886098108e-05\n",
      "310 1.8833742353e-05\n",
      "311 1.81079644362e-05\n",
      "312 1.74101550716e-05\n",
      "313 1.6739236468e-05\n",
      "314 1.60941723679e-05\n",
      "315 1.54739664463e-05\n",
      "316 1.48776607721e-05\n",
      "317 1.43043343289e-05\n",
      "318 1.3753101592e-05\n",
      "319 1.32231111612e-05\n",
      "320 1.27135444452e-05\n",
      "321 1.22236143981e-05\n",
      "322 1.17525643029e-05\n",
      "323 1.12996666036e-05\n",
      "324 1.08642217809e-05\n",
      "325 1.0445557272e-05\n",
      "326 1.00430264319e-05\n",
      "327 9.65600753441e-06\n",
      "328 9.28390281216e-06\n",
      "329 8.92613753314e-06\n",
      "330 8.58215911315e-06\n",
      "331 8.25143626222e-06\n",
      "332 7.93345816411e-06\n",
      "333 7.62773368729e-06\n",
      "334 7.3337906264e-06\n",
      "335 7.05117497292e-06\n",
      "336 6.77945021393e-06\n",
      "337 6.51819665793e-06\n",
      "338 6.26701078658e-06\n",
      "339 6.02550463149e-06\n",
      "340 5.793305175e-06\n",
      "341 5.57005377399e-06\n",
      "342 5.355405606e-06\n",
      "343 5.14902913661e-06\n",
      "344 4.95060560741e-06\n",
      "345 4.75982854362e-06\n",
      "346 4.57640328076e-06\n",
      "347 4.40004650954e-06\n",
      "348 4.23048583824e-06\n",
      "349 4.06745937205e-06\n",
      "350 3.9107153085e-06\n",
      "351 3.76001154859e-06\n",
      "352 3.61511532285e-06\n",
      "353 3.47580283178e-06\n",
      "354 3.34185890026e-06\n",
      "355 3.21307664512e-06\n",
      "356 3.08925715566e-06\n",
      "357 2.9702091864e-06\n",
      "358 2.85574886169e-06\n",
      "359 2.74569939173e-06\n",
      "360 2.6398907995e-06\n",
      "361 2.53815965818e-06\n",
      "362 2.44034883882e-06\n",
      "363 2.34630726756e-06\n",
      "364 2.25588969234e-06\n",
      "365 2.16895645855e-06\n",
      "366 2.08537329331e-06\n",
      "367 2.00501109806e-06\n",
      "368 1.92774574924e-06\n",
      "369 1.85345790647e-06\n",
      "370 1.7820328283e-06\n",
      "371 1.71336019498e-06\n",
      "372 1.64733393802e-06\n",
      "373 1.58385207641e-06\n",
      "374 1.52281655908e-06\n",
      "375 1.46413311345e-06\n",
      "376 1.40771109987e-06\n",
      "377 1.35346337155e-06\n",
      "378 1.30130614001e-06\n",
      "379 1.25115884566e-06\n",
      "380 1.20294403334e-06\n",
      "381 1.15658723272e-06\n",
      "382 1.11201684326e-06\n",
      "383 1.06916402363e-06\n",
      "384 1.02796258538e-06\n",
      "385 9.88348890689e-07\n",
      "386 9.50261754097e-07\n",
      "387 9.13642347993e-07\n",
      "388 8.7843411175e-07\n",
      "389 8.44582664369e-07\n",
      "390 8.12035720482e-07\n",
      "391 7.80743009592e-07\n",
      "392 7.50656198435e-07\n",
      "393 7.21728816319e-07\n",
      "394 6.93916183354e-07\n",
      "395 6.67175341437e-07\n",
      "396 6.41464987903e-07\n",
      "397 6.16745411731e-07\n",
      "398 5.92978432208e-07\n",
      "399 5.70127339959e-07\n",
      "400 5.48156840241e-07\n",
      "401 5.27032998437e-07\n",
      "402 5.06723187636e-07\n",
      "403 4.87196038242e-07\n",
      "404 4.68421389522e-07\n",
      "405 4.50370243018e-07\n",
      "406 4.33014717762e-07\n",
      "407 4.16328007208e-07\n",
      "408 4.00284337833e-07\n",
      "409 3.84858929323e-07\n",
      "410 3.70027956301e-07\n",
      "411 3.5576851153e-07\n",
      "412 3.42058570526e-07\n",
      "413 3.28876957544e-07\n",
      "414 3.1620331287e-07\n",
      "415 3.04018061376e-07\n",
      "416 2.92302382281e-07\n",
      "417 2.81038180085e-07\n",
      "418 2.70208056617e-07\n",
      "419 2.59795284167e-07\n",
      "420 2.49783779642e-07\n",
      "421 2.40158079733e-07\n",
      "422 2.30903317024e-07\n",
      "423 2.22005197033e-07\n",
      "424 2.13449976131e-07\n",
      "425 2.05224440316e-07\n",
      "426 1.97315884802e-07\n",
      "427 1.89712094396e-07\n",
      "428 1.82401324632e-07\n",
      "429 1.75372283628e-07\n",
      "430 1.68614114651e-07\n",
      "431 1.6211637934e-07\n",
      "432 1.55869041592e-07\n",
      "433 1.49862452054e-07\n",
      "434 1.44087333223e-07\n",
      "435 1.38534765113e-07\n",
      "436 1.33196171483e-07\n",
      "437 1.28063306584e-07\n",
      "438 1.23128242427e-07\n",
      "439 1.18383356539e-07\n",
      "440 1.13821320184e-07\n",
      "441 1.09435087051e-07\n",
      "442 1.05217882363e-07\n",
      "443 1.01163192419e-07\n",
      "444 9.72647545298e-08\n",
      "445 9.35165473464e-08\n",
      "446 8.99127815589e-08\n",
      "447 8.64478909551e-08\n",
      "448 8.31165238233e-08\n",
      "449 7.99135346858e-08\n",
      "450 7.68339763517e-08\n",
      "451 7.38730922756e-08\n",
      "452 7.10263092112e-08\n",
      "453 6.82892301472e-08\n",
      "454 6.56576275159e-08\n",
      "455 6.31274366642e-08\n",
      "456 6.06947495746e-08\n",
      "457 5.83558088295e-08\n",
      "458 5.61070018079e-08\n",
      "459 5.39448551048e-08\n",
      "460 5.18660291671e-08\n",
      "461 4.9867313135e-08\n",
      "462 4.79456198829e-08\n",
      "463 4.60979812509e-08\n",
      "464 4.43215434606e-08\n",
      "465 4.26135627074e-08\n",
      "466 4.09714009217e-08\n",
      "467 3.93925216956e-08\n",
      "468 3.7874486364e-08\n",
      "469 3.64149502389e-08\n",
      "470 3.50116589871e-08\n",
      "471 3.3662445149e-08\n",
      "472 3.23652247904e-08\n",
      "473 3.11179942838e-08\n",
      "474 2.99188272138e-08\n",
      "475 2.87658714016e-08\n",
      "476 2.76573460442e-08\n",
      "477 2.65915389638e-08\n",
      "478 2.55668039634e-08\n",
      "479 2.4581558284e-08\n",
      "480 2.363428016e-08\n",
      "481 2.27235064688e-08\n",
      "482 2.18478304708e-08\n",
      "483 2.10058996367e-08\n",
      "484 2.01964135585e-08\n",
      "485 1.9418121941e-08\n",
      "486 1.86698226703e-08\n",
      "487 1.79503599575e-08\n",
      "488 1.72586225532e-08\n",
      "489 1.65935420314e-08\n",
      "490 1.5954091139e-08\n",
      "491 1.53392822092e-08\n",
      "492 1.47481656362e-08\n",
      "493 1.41798284082e-08\n",
      "494 1.36333926976e-08\n",
      "495 1.31080145044e-08\n",
      "496 1.26028823535e-08\n",
      "497 1.21172160408e-08\n",
      "498 1.16502654283e-08\n",
      "499 1.12013092852e-08\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "learning_rate = .01\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "\n",
    "    #A relu is just the activation.\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CFully connected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.99992661]\n",
      " [ 1.00007337]\n",
      " [ 0.        ]] \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = np.maximum(x.dot(w1),0).dot(w2)\n",
    "\n",
    "print (pred, \"\\n\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layers are Often Viewed as Unknown\n",
    "- Just a weighting matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20401151,  1.01377406],\n",
       "       [-0.10186284,  1.01392285],\n",
       "       [ 1.07856887,  0.01873049]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#However\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49346731],\n",
       "       [ 0.98634069]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.72108356,  0.        ,  0.        ],\n",
       "       [ 0.72753913,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relu just removes the negative numbers.  \n",
    "h_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
