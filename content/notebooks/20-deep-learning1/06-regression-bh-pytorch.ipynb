{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"regression-boston-housing-pytorch.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/rpi-techfundamentals/fall2018-materials/blob/master/07-intro-modeling2/02-regression-boston-housing-python.ipynb","timestamp":1543276896373}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"slideshow":{"slide_type":"slide"},"id":"PAq3-v_peF9P","colab_type":"text"},"cell_type":"markdown","source":["[![AnalyticsDojo](https://github.com/rpi-techfundamentals/fall2018-materials/blob/master/fig/final-logo.png?raw=1)](http://rpi.analyticsdojo.com)\n","<center><h1>Revisting Boston Housing with Pytorch</h1></center>\n","<center><h3><a href = 'http://rpi.analyticsdojo.com'>rpi.analyticsdojo.com</a></h3></center>"]},{"metadata":{"id":"ssNHzVxmeUho","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install torch torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0Usm1-07eF9U","colab_type":"code","colab":{}},"cell_type":"code","source":["#Let's get rid of some imports\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","#Define the model \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"ey6rkOdbeF9d","colab_type":"text"},"cell_type":"markdown","source":["## Overview\n","- Getting the Data\n","- Reviewing Data\n","- Modeling \n","- Model Evaluation\n","- Using Model\n","- Storing Model\n"]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"3wcvspWkeF9f","colab_type":"text"},"cell_type":"markdown","source":["## Getting Data \n","- Available in the [sklearn package](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) as a Bunch object (dictionary).\n","- From FAQ: [\"Donâ€™t make a bunch object! They are not part of the scikit-learn API. Bunch objects are just a way to package some numpy arrays. As a scikit-learn user you only ever need numpy arrays to feed your model with data.\"](http://scikit-learn.org/stable/faq.html)\n","- Available in the UCI data repository. \n","- Better to convert to Pandas dataframe. "]},{"metadata":{"id":"r8nkKvL4eF9o","colab_type":"code","colab":{}},"cell_type":"code","source":["#From sklearn tutorial.\n","from sklearn.datasets import load_boston\n","boston = load_boston()\n","print( \"Type of boston dataset:\", type(boston))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dBPIWOQDeF9s","colab_type":"code","colab":{}},"cell_type":"code","source":["#A bunch is you remember is a dictionary based dataset.  Dictionaries are addressed by keys. \n","#Let's look at the keys. \n","print(boston.keys())\n"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"mFOdZXNKeF9x","colab_type":"code","colab":{}},"cell_type":"code","source":["#DESCR sounds like it could be useful. Let's print the description.\n","print(boston['DESCR'])"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"GFUWt9YJeF92","colab_type":"code","colab":{}},"cell_type":"code","source":["# Let's change the data to a Panda's Dataframe\n","import pandas as pd\n","boston_df = pd.DataFrame(boston['data'] )\n","boston_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"PmWBxnVNeF95","colab_type":"code","colab":{}},"cell_type":"code","source":["#Now add the column names.\n","boston_df.columns = boston['feature_names']\n","boston_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"bSqG7J-GeF99","colab_type":"code","colab":{}},"cell_type":"code","source":["#Add the target as PRICE. \n","boston_df['PRICE']= boston['target']\n","boston_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"cJHf2nYceF-B","colab_type":"text"},"cell_type":"markdown","source":[" ## Attribute Information (in order):\n"," Looks like they are all continuous IV and continuous DV. \n","        - CRIM     per capita crime rate by town\n","        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n","        - INDUS    proportion of non-retail business acres per town\n","        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n","        - NOX      nitric oxides concentration (parts per 10 million)\n","        - RM       average number of rooms per dwelling\n","        - AGE      proportion of owner-occupied units built prior to 1940\n","        - DIS      weighted distances to five Boston employment centres\n","        - RAD      index of accessibility to radial highways\n","        - TAX      full-value property-tax rate per 10,000\n","        - PTRATIO  pupil-teacher ratio by town\n","        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n","        - LSTAT    % lower status of the population\n","        - MEDV     Median value of owner-occupied homes in 1000's\n"," Let's check for missing values."]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"17iYyvMNeF-D","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","#check for missing values\n","print(np.sum(np.isnan(boston_df)))"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"31VBYJCXeF-K","colab_type":"text"},"cell_type":"markdown","source":["## What type of data are there?\n","- First let's focus on the dependent variable, as the nature of the DV is critical to selection of model. \n","- *Median value of owner-occupied homes in $1000's* is the Dependent Variable  (continuous variable).\n","- It is relevant to look at the distribution of the dependent variable, so let's do that first.\n","- Here there is a normal distribution for the most part, with some at the top end of the distribution we could explore later."]},{"metadata":{"id":"gMC1ywHPeF-N","colab_type":"code","colab":{}},"cell_type":"code","source":["#Let's us seaborn, because it is pretty. ;) \n","#See more here. http://seaborn.pydata.org/tutorial/distributions.html\n","import seaborn as sns\n","sns.distplot(boston_df['PRICE']);"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"7uq7gI9seF-R","colab_type":"code","colab":{}},"cell_type":"code","source":["#We can quickly look at other data. \n","#Look at the bottom row to see thinks likely coorelated with price. \n","#Look along the diagonal to see histograms of each. \n","sns.pairplot(boston_df);"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"Zfa7DQNheF-U","colab_type":"text"},"cell_type":"markdown","source":["## Preparing to Model \n","- It is common to separate `y` as the dependent variable and `X` as the matrix of independent variables.\n","- Here we are using `train_test_split` to split the test and train.\n","- This creates 4 subsets, with IV and DV separted: `X_train, X_test, y_train, y_test`\n"," \n"]},{"metadata":{"id":"89UDBeWFeF-W","colab_type":"code","colab":{}},"cell_type":"code","source":["#This will throw and error at import if haven't upgraded. \n","# from sklearn.cross_validation  import train_test_split  \n","from sklearn.model_selection  import train_test_split\n","#y is the dependent variable.\n","y = boston_df['PRICE']\n","#As we know, iloc is used to slice the array by index number. Here this is the matrix of \n","#independent variables.\n","X = boston_df.iloc[:,0:13]\n","\n","# Split the data into a training set and a test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n","\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PbbYVzFTfAJL","colab_type":"code","colab":{}},"cell_type":"code","source":["#Define training hyperprameters.\n","batch_size = 50\n","num_epochs = 200\n","learning_rate = 0.01\n","size_hidden= 100\n","\n","#Calculate some other hyperparameters based on data.  \n","batch_no = len(X_train) // batch_size  #batches\n","cols=X_train.shape[1] #Number of columns in input matrix\n","n_output=1\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xD9PhAU7hoqT","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create the model\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# Assume that we are on a CUDA machine, then this should print a CUDA device:\n","print(\"Executing the model on :\",device)\n","class Net(torch.nn.Module):\n","    def __init__(self, n_feature, size_hidden, n_output):\n","        super(Net, self).__init__()\n","        self.hidden = torch.nn.Linear(cols, size_hidden)   # hidden layer\n","        self.predict = torch.nn.Linear(size_hidden, n_output)   # output layer\n","\n","    def forward(self, x):\n","        x = F.relu(self.hidden(x))      # activation function for hidden layer\n","        x = self.predict(x)             # linear output\n","        return x\n","net = Net(cols, size_hidden, n_output)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dE9a54SijQEs","colab_type":"code","colab":{}},"cell_type":"code","source":["#Adam is a specific flavor of gradient decent which is typically better\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n","criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J1-OhvPsk6aM","colab_type":"code","colab":{}},"cell_type":"code","source":["#Change to numpy arraay. \n","X_train=X_train.values\n","y_train=y_train.values\n","X_test=X_test.values\n","y_test=y_test.values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nyf8hhaijqFA","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.utils import shuffle\n","from torch.autograd import Variable\n","running_loss = 0.0\n","for epoch in range(num_epochs):\n","    #Shuffle just mixes up the dataset between epocs\n","    X_train, y_train = shuffle(X_train, y_train)\n","    # Mini batch learning\n","    for i in range(batch_no):\n","        start = i * batch_size\n","        end = start + batch_size\n","        inputs = Variable(torch.FloatTensor(X_train[start:end]))\n","        labels = Variable(torch.FloatTensor(y_train[start:end]))\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        #print(\"outputs\",outputs)\n","        #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n","        loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        \n","    print('Epoch {}'.format(epoch+1), \"loss: \",running_loss)\n","    running_loss = 0.0\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n4QTTcBF3aeZ","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","import pandas as pd\n","from sklearn.metrics import r2_score\n","\n","X = Variable(torch.FloatTensor(X_train)) \n","result = net(X)\n","pred=result.data[:,0].numpy()\n","print(len(pred),len(y_train))\n","r2_score(pred,y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rAsEl1qyuSrH","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import r2_score\n","#This is a little bit tricky to get the resulting prediction.  \n","def calculate_r2(x,y=[]):\n","    \"\"\"\n","    This function will return the r2 if passed x and y or return predictions if just passed x. \n","    \"\"\"\n","    # Evaluate the model with the test set. \n","    X = Variable(torch.FloatTensor(x))  \n","    result = net(X) #This outputs the value for regression\n","    result=result.data[:,0].numpy()\n","  \n","    if len(y) != 0:\n","        r2=r2_score(result, y)\n","        print(\"R-Squared\", r2)\n","        #print('Accuracy {:.2f}'.format(num_right / len(y)), \"for a total of \", len(y), \"records\")\n","        return pd.DataFrame(data= {'actual': y, 'predicted': result})\n","    else:\n","        print(\"returning predictions\")\n","        return result\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WJ451DaG5yXb","colab_type":"code","colab":{}},"cell_type":"code","source":["result1=calculate_r2(X_train,y_train)\n","result2=calculate_r2(X_test,y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"v4mhnevoeF-Y","colab_type":"text"},"cell_type":"markdown","source":["## Modeling \n","- First import the package: `from sklearn.linear_model import LinearRegression`\n","- Then create the model object.  \n","- Then fit the data. \n","- This creates a trained model (an object) of class regression.\n","- The variety of methods and attributes available for regression are shown [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n"]},{"metadata":{"id":"CcWl-I5BeF-Z","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","lm = LinearRegression()\n","lm.fit( X_train, y_train )\n"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"id":"fbnv9I0ueF-e","colab_type":"text"},"cell_type":"markdown","source":["## Evaluating the Model Results\n","- You have fit a model. \n","- You can now store this model, save the object to disk, or evaluate it with different outcomes. \n","- Trained regression objects have coefficients (`coef_`) and intercepts (`intercept_`) as attributes. \n","- R-Squared is determined from the `score` method of the regression object.\n","- For Regression, we are going to use the coefficient of determination as our way of evaluating the results, [also referred to as R-Squared](https://en.wikipedia.org/wiki/Coefficient_of_determination)"]},{"metadata":{"id":"lkam3qKNeF-f","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","print('R2 for Train)', lm.score( X_train, y_train ))\n","print('R2 for Test (cross validation)', lm.score(X_test, y_test))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E-oXxeTweF_G","colab_type":"text"},"cell_type":"markdown","source":["\n","Copyright [AnalyticsDojo](http://rpi.analyticsdojo.com) 2016.\n","This work is licensed under the [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/) license agreement.\n"]}]}