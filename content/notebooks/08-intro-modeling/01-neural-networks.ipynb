{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-Neural-Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6yF_rLV5Q4L",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks and the Simplist XOR Problem\n",
        "- This was adopted from the PyTorch Tutorials. \n",
        "- Simple supervised machine learning.\n",
        "- http://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N8bijcQ5Q4Q",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks \n",
        "- Neural networks are the foundation of deep learning, which has revolutionized the \n",
        "\n",
        "```In the mathematical theory of artificial neural networks, the universal approximation theorem states[1] that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of Rn, under mild assumptions on the activation function.```\n",
        "\n",
        "- A simple task that Neural Networks can do but simple linear models cannot is called the [XOR problem](https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b).\n",
        "\n",
        "- The XOR problem involves an output being 1 if either of two inputs is 1, but not both. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK5CNxwO5Q4T",
        "colab_type": "text"
      },
      "source": [
        "### Generate Fake Data\n",
        "- `D_in` is the number of dimensions of an input varaible.\n",
        "- `D_out` is the number of dimentions of an output variable.\n",
        "- Here we are learning some special \"fake\" data that represents the xor problem. \n",
        "- Here, the dv is 1 if either the first or second variable is \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Pm-EXK5Q4W",
        "colab_type": "code",
        "outputId": "62b36196-da4f-4349-aea8-ca919195813a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "\n",
        "#This is our independent and dependent variables. \n",
        "x = np.array([ [0,0,0],[1,0,0],[0,1,0],[0,0,0] ])\n",
        "y = np.array([[0,1,1,0]]).T\n",
        "print(\"Input data:\\n\",x,\"\\n Output data:\\n\",y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:\n",
            " [[0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]] \n",
            " Output data:\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx3UZLcC5Q4m",
        "colab_type": "text"
      },
      "source": [
        "### A Simple Neural Network \n",
        "- Here we are going to build a neural network. \n",
        "- First layer (`D_in`)has to be the length of the input.\n",
        "- `H` is the length of the output.\n",
        "-  `D_out` is 1 as it will be the probability it is a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtPFUCoR5Q4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(seed=83832)\n",
        "#D_in is the number of input variables. \n",
        "#H is the hidden dimension.\n",
        "#D_out is the number of dimensions for the output. \n",
        "D_in, H, D_out = 3, 2, 1\n",
        "\n",
        "# Randomly initialize weights og out 2 hidden layer network.\n",
        "w1 = np.random.randn(D_in, H)\n",
        "w2 = np.random.randn(H, D_out)\n",
        "bias = np.random.randn(H, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYXsVn3z8AR-",
        "colab_type": "text"
      },
      "source": [
        "### But \"Hidden Layers\" Aren't Hidden\n",
        "- Let's take a look \n",
        "- These are just random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxVP_1eI62BT",
        "colab_type": "code",
        "outputId": "fcced21f-9ca8-4d9d-edbf-6bdff9e99db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "print(w1, w2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.20401151  0.62388689]\n",
            " [-0.10186284  1.47372825]\n",
            " [ 1.07856887  0.01873049]] [[ 0.49346731]\n",
            " [-1.19376828]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fk9EaZ89TGb",
        "colab_type": "text"
      },
      "source": [
        "### Update the Weights using Gradient Decent\n",
        "- Calculate the predited value\n",
        "- Calculate the loss function\n",
        "- Compute the gradients of w1 and w2 with respect to the loss function\n",
        "- Update the weights using the learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEn83e_t5Q40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6ef0176-db06-468a-8978-6a2b70717b1d"
      },
      "source": [
        "learning_rate = .01\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.dot(w1)\n",
        "\n",
        "    #A relu is just the activation.\n",
        "    h_relu = np.maximum(h, 0)\n",
        "    y_pred = h_relu.dot(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = np.square(y_pred - y).sum()\n",
        "    print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
        "    grad_h = grad_h_relu.copy()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.T.dot(grad_h)\n",
        "\n",
        "    # Update weights\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 10.65792615907139\n",
            "1 9.10203339892777\n",
            "2 7.928225580610054\n",
            "3 7.016030709608875\n",
            "4 6.289798199184453\n",
            "5 5.699847385692147\n",
            "6 5.2123305302347624\n",
            "7 4.803466247932402\n",
            "8 4.456102755004962\n",
            "9 4.1575876890269665\n",
            "10 3.898402733982808\n",
            "11 3.671262676836925\n",
            "12 3.4705056296083194\n",
            "13 3.291670966818706\n",
            "14 3.1312013137273507\n",
            "15 2.9862283397788603\n",
            "16 2.854416299096229\n",
            "17 2.733846078586037\n",
            "18 2.622928124188624\n",
            "19 2.5203362600714687\n",
            "20 2.4249568284296723\n",
            "21 2.335849203166264\n",
            "22 2.2522148435722413\n",
            "23 2.173372827242625\n",
            "24 2.0987403459205147\n",
            "25 2.0278170362586616\n",
            "26 1.9601722976944669\n",
            "27 1.8954349540796849\n",
            "28 1.8332847664299674\n",
            "29 1.773445416375481\n",
            "30 1.7156786642283006\n",
            "31 1.6597794495384952\n",
            "32 1.6055717509418743\n",
            "33 1.5529050598636533\n",
            "34 1.5016513520352168\n",
            "35 1.4517024638575724\n",
            "36 1.402967798918812\n",
            "37 1.3553723045677533\n",
            "38 1.3088546702007282\n",
            "39 1.2633657084618402\n",
            "40 1.2188668883615361\n",
            "41 1.175328995740111\n",
            "42 1.1327309018102432\n",
            "43 1.0910584249086992\n",
            "44 1.0503032742251954\n",
            "45 1.0104620672725408\n",
            "46 0.9715354153057676\n",
            "47 0.9335270728583867\n",
            "48 0.8964431490967778\n",
            "49 0.8602913798451839\n",
            "50 0.8250804599443017\n",
            "51 0.7908194361131566\n",
            "52 0.7575171607226662\n",
            "53 0.725181806895671\n",
            "54 0.6938204451583221\n",
            "55 0.6634386815182467\n",
            "56 0.6340403563729178\n",
            "57 0.6056273030939351\n",
            "58 0.5781991645253675\n",
            "59 0.5517532650109411\n",
            "60 0.5262845349569829\n",
            "61 0.5017854843733736\n",
            "62 0.4782462213367543\n",
            "63 0.45565451090747644\n",
            "64 0.4339958697177296\n",
            "65 0.4132536912411343\n",
            "66 0.39340939665695995\n",
            "67 0.3744426062333802\n",
            "68 0.3563313262679901\n",
            "69 0.339052146830798\n",
            "70 0.3225804458429691\n",
            "71 0.3068905953796952\n",
            "72 0.2919561664924972\n",
            "73 0.27775012928952875\n",
            "74 0.26424504547683114\n",
            "75 0.25141325103470336\n",
            "76 0.23922702716849936\n",
            "77 0.2276587581210479\n",
            "78 0.2166810748552383\n",
            "79 0.20626698400286633\n",
            "80 0.1963899818243421\n",
            "81 0.1870241532299702\n",
            "82 0.17814425617563434\n",
            "83 0.16972579196376805\n",
            "84 0.1617450621557261\n",
            "85 0.1541792129363326\n",
            "86 0.147006267868564\n",
            "87 0.140205150039638\n",
            "88 0.13375569463319448\n",
            "89 0.1276386529698942\n",
            "90 0.1218356890447229\n",
            "91 0.11632936955756723\n",
            "92 0.11110314838793904\n",
            "93 0.1061413464085187\n",
            "94 0.10142912746853275\n",
            "95 0.09695247130958222\n",
            "96 0.09269814410571503\n",
            "97 0.08865366724822979\n",
            "98 0.08480728492549391\n",
            "99 0.0811479309802164\n",
            "100 0.07766519546208477\n",
            "101 0.07434929123315356\n",
            "102 0.0711910209273244\n",
            "103 0.06818174451394585\n",
            "104 0.06531334766910445\n",
            "105 0.06257821111654908\n",
            "106 0.05996918106326466\n",
            "107 0.05747954082229276\n",
            "108 0.05510298368722062\n",
            "109 0.052833587098539955\n",
            "110 0.050665788121483174\n",
            "111 0.04859436023766026\n",
            "112 0.046614391438508374\n",
            "113 0.044721263596905425\n",
            "114 0.042910633083986426\n",
            "115 0.04117841259093982\n",
            "116 0.0395207541100794\n",
            "117 0.03793403302553889\n",
            "118 0.03641483326129067\n",
            "119 0.03495993343264216\n",
            "120 0.03356629394672944\n",
            "121 0.0322310449976488\n",
            "122 0.03095147540259279\n",
            "123 0.029725022226571782\n",
            "124 0.028549261144892105\n",
            "125 0.027421897494436413\n",
            "126 0.0263407579668736\n",
            "127 0.025303782899147254\n",
            "128 0.02430901911889927\n",
            "129 0.023354613304830955\n",
            "130 0.0224388058243556\n",
            "131 0.021559925013216318\n",
            "132 0.02071638186401746\n",
            "133 0.019906665092819995\n",
            "134 0.019129336555072554\n",
            "135 0.01838302698417915\n",
            "136 0.017666432027935646\n",
            "137 0.016978308559893886\n",
            "138 0.016317471244437356\n",
            "139 0.015682789335971285\n",
            "140 0.015073183694146064\n",
            "141 0.014487623998449207\n",
            "142 0.01392512614681838\n",
            "143 0.013384749824153785\n",
            "144 0.012865596227742457\n",
            "145 0.01236680593765744\n",
            "146 0.011887556921165793\n",
            "147 0.01142706266107241\n",
            "148 0.010984570398752825\n",
            "149 0.010559359483383497\n",
            "150 0.010150739819576832\n",
            "151 0.009758050406265562\n",
            "152 0.009380657960268358\n",
            "153 0.009017955618505363\n",
            "154 0.00866936171332396\n",
            "155 0.008334318615846222\n",
            "156 0.008012291642660496\n",
            "157 0.007702768021557011\n",
            "158 0.0074052559123513875\n",
            "159 0.007119283479154988\n",
            "160 0.00684439801073854\n",
            "161 0.006580165085898312\n",
            "162 0.006326167780975099\n",
            "163 0.0060820059168944065\n",
            "164 0.005847295343298466\n",
            "165 0.005621667257523059\n",
            "166 0.00540476755634021\n",
            "167 0.00519625621854179\n",
            "168 0.004995806716578387\n",
            "169 0.004803105455597478\n",
            "170 0.004617851238342064\n",
            "171 0.004439754754478814\n",
            "172 0.004268538093024131\n",
            "173 0.004103934276626908\n",
            "174 0.003945686816550616\n",
            "175 0.0037935492872733776\n",
            "176 0.0036472849196956558\n",
            "177 0.003506666212010064\n",
            "178 0.0033714745573471235\n",
            "179 0.0032414998873664088\n",
            "180 0.0031165403310131914\n",
            "181 0.002996401887707673\n",
            "182 0.0028808981142773157\n",
            "183 0.0027698498249834596\n",
            "184 0.002663084804030042\n",
            "185 0.002560437529977551\n",
            "186 0.0024617489115170118\n",
            "187 0.0023668660340890185\n",
            "188 0.0022756419168604115\n",
            "189 0.002187935279597463\n",
            "190 0.002103610318998506\n",
            "191 0.0020225364940712155\n",
            "192 0.0019445883201617943\n",
            "193 0.0018696451712621129\n",
            "194 0.0017975910902400137\n",
            "195 0.0017283146066554844\n",
            "196 0.0016617085618411765\n",
            "197 0.0015976699409418664\n",
            "198 0.0015360997116213772\n",
            "199 0.001476902669159437\n",
            "200 0.0014199872876736073\n",
            "201 0.0013652655772137235\n",
            "202 0.0013126529464877815\n",
            "203 0.0012620680709887451\n",
            "204 0.0012134327663025218\n",
            "205 0.0011666718663866913\n",
            "206 0.0011217131066188356\n",
            "207 0.0010784870114223695\n",
            "208 0.0010369267862857035\n",
            "209 0.000996968213998663\n",
            "210 0.0009585495549376858\n",
            "211 0.0009216114512381271\n",
            "212 0.0008860968346992506\n",
            "213 0.0008519508382735161\n",
            "214 0.0008191207109983951\n",
            "215 0.0007875557362343561\n",
            "216 0.000757207153078624\n",
            "217 0.0007280280808296751\n",
            "218 0.0006999734463822273\n",
            "219 0.000672999914437815\n",
            "220 0.0006470658204202973\n",
            "221 0.000622131105990457\n",
            "222 0.0005981572570579552\n",
            "223 0.0005751072441928266\n",
            "224 0.0005529454653431726\n",
            "225 0.0005316376907686722\n",
            "226 0.0005111510101038712\n",
            "227 0.0004914537814680439\n",
            "228 0.0004725155825422385\n",
            "229 0.0004543071635367196\n",
            "230 0.0004368004019756303\n",
            "231 0.00041996825922807537\n",
            "232 0.0004037847387179752\n",
            "233 0.00038822484574746864\n",
            "234 0.000373264548871404\n",
            "235 0.0003588807427627314\n",
            "236 0.0003450512125110722\n",
            "237 0.00033175459929894827\n",
            "238 0.00031897036740236116\n",
            "239 0.00030667877246449906\n",
            "240 0.00029486083099329336\n",
            "241 0.00028349829103548963\n",
            "242 0.0002725736039817843\n",
            "243 0.0002620698974593076\n",
            "244 0.0002519709492694341\n",
            "245 0.00024226116233050105\n",
            "246 0.00023292554058671085\n",
            "247 0.00022394966584582068\n",
            "248 0.00021531967550979456\n",
            "249 0.00020702224116398246\n",
            "250 0.00019904454799161983\n",
            "251 0.0001913742749818817\n",
            "252 0.0001839995759008063\n",
            "253 0.00017690906099565552\n",
            "254 0.00017009177940448836\n",
            "255 0.00016353720224369502\n",
            "256 0.00015723520634729167\n",
            "257 0.00015117605863298604\n",
            "258 0.00014535040107069527\n",
            "259 0.00013974923623037293\n",
            "260 0.00013436391338677672\n",
            "261 0.0001291861151597235\n",
            "262 0.00012420784466916755\n",
            "263 0.00011942141318526729\n",
            "264 0.00011481942825437294\n",
            "265 0.00011039478228253808\n",
            "266 0.00010614064155901145\n",
            "267 0.0001020504357026523\n",
            "268 9.811784751502961e-05\n",
            "269 9.433680322452288e-05\n",
            "270 9.07014631063634e-05\n",
            "271 8.720621246405432e-05\n",
            "272 8.384565295836376e-05\n",
            "273 8.06145942704182e-05\n",
            "274 7.750804608602226e-05\n",
            "275 7.45212103888556e-05\n",
            "276 7.16494740506235e-05\n",
            "277 6.888840170673525e-05\n",
            "278 6.623372890648624e-05\n",
            "279 6.36813555272088e-05\n",
            "280 6.122733944212446e-05\n",
            "281 5.8867890432272306e-05\n",
            "282 5.659936433295092e-05\n",
            "283 5.4418257405766915e-05\n",
            "284 5.232120092748597e-05\n",
            "285 5.030495598744348e-05\n",
            "286 4.8366408485379654e-05\n",
            "287 4.650256432203307e-05\n",
            "288 4.4710544775062853e-05\n",
            "289 4.2987582053132594e-05\n",
            "290 4.1331015021312185e-05\n",
            "291 3.9738285091188996e-05\n",
            "292 3.8206932269354095e-05\n",
            "293 3.673459135812327e-05\n",
            "294 3.531898830268317e-05\n",
            "295 3.3957936678981286e-05\n",
            "296 3.2649334316941296e-05\n",
            "297 3.139116005380407e-05\n",
            "298 3.0181470612568156e-05\n",
            "299 2.901839760070956e-05\n",
            "300 2.790014462456529e-05\n",
            "301 2.6824984514883835e-05\n",
            "302 2.579125665930827e-05\n",
            "303 2.479736443763488e-05\n",
            "304 2.3841772755898297e-05\n",
            "305 2.2923005675484053e-05\n",
            "306 2.2039644133597908e-05\n",
            "307 2.119032375156838e-05\n",
            "308 2.0373732727611678e-05\n",
            "309 1.958860981078675e-05\n",
            "310 1.8833742353025982e-05\n",
            "311 1.8107964436237772e-05\n",
            "312 1.7410155071560296e-05\n",
            "313 1.673923646802122e-05\n",
            "314 1.6094172367903756e-05\n",
            "315 1.547396644626215e-05\n",
            "316 1.4877660772109866e-05\n",
            "317 1.430433432890405e-05\n",
            "318 1.3753101592043518e-05\n",
            "319 1.3223111161177204e-05\n",
            "320 1.271354444522436e-05\n",
            "321 1.2223614398052364e-05\n",
            "322 1.1752564302897218e-05\n",
            "323 1.1299666603598998e-05\n",
            "324 1.0864221780898391e-05\n",
            "325 1.0445557272020895e-05\n",
            "326 1.0043026431896353e-05\n",
            "327 9.656007534414035e-06\n",
            "328 9.283902812157043e-06\n",
            "329 8.926137533144259e-06\n",
            "330 8.582159113149512e-06\n",
            "331 8.251436262223122e-06\n",
            "332 7.933458164113636e-06\n",
            "333 7.627733687293064e-06\n",
            "334 7.33379062640477e-06\n",
            "335 7.051174972921215e-06\n",
            "336 6.779450213931473e-06\n",
            "337 6.518196657925287e-06\n",
            "338 6.267010786575047e-06\n",
            "339 6.025504631492694e-06\n",
            "340 5.793305174999138e-06\n",
            "341 5.570053773989272e-06\n",
            "342 5.355405605998847e-06\n",
            "343 5.149029136614468e-06\n",
            "344 4.9506056074123485e-06\n",
            "345 4.759828543619497e-06\n",
            "346 4.576403280761419e-06\n",
            "347 4.4000465095373554e-06\n",
            "348 4.230485838242033e-06\n",
            "349 4.0674593720484435e-06\n",
            "350 3.91071530849992e-06\n",
            "351 3.760011548592869e-06\n",
            "352 3.615115322845847e-06\n",
            "353 3.4758028317824277e-06\n",
            "354 3.3418589002573495e-06\n",
            "355 3.2130766451173086e-06\n",
            "356 3.0892571556569434e-06\n",
            "357 2.9702091863957054e-06\n",
            "358 2.8557488616903765e-06\n",
            "359 2.7456993917342825e-06\n",
            "360 2.6398907994953916e-06\n",
            "361 2.538159658179872e-06\n",
            "362 2.4403488388159694e-06\n",
            "363 2.3463072675564664e-06\n",
            "364 2.2558896923420854e-06\n",
            "365 2.1689564585528806e-06\n",
            "366 2.0853732933059644e-06\n",
            "367 2.0050110980633565e-06\n",
            "368 1.9277457492352228e-06\n",
            "369 1.8534579064655777e-06\n",
            "370 1.7820328283025376e-06\n",
            "371 1.7133601949808364e-06\n",
            "372 1.6473339380218593e-06\n",
            "373 1.5838520764096164e-06\n",
            "374 1.5228165590753771e-06\n",
            "375 1.464133113451991e-06\n",
            "376 1.40771109986799e-06\n",
            "377 1.3534633715480287e-06\n",
            "378 1.3013061400118565e-06\n",
            "379 1.2511588456580528e-06\n",
            "380 1.202944033337219e-06\n",
            "381 1.156587232716991e-06\n",
            "382 1.1120168432603495e-06\n",
            "383 1.0691640236341087e-06\n",
            "384 1.0279625853816399e-06\n",
            "385 9.883488906893815e-07\n",
            "386 9.502617540972218e-07\n",
            "387 9.136423479925375e-07\n",
            "388 8.784341117501692e-07\n",
            "389 8.445826643692572e-07\n",
            "390 8.120357204815001e-07\n",
            "391 7.807430095922277e-07\n",
            "392 7.506561984347445e-07\n",
            "393 7.217288163193481e-07\n",
            "394 6.939161833544208e-07\n",
            "395 6.671753414368786e-07\n",
            "396 6.41464987902722e-07\n",
            "397 6.167454117308101e-07\n",
            "398 5.929784322084336e-07\n",
            "399 5.701273399586136e-07\n",
            "400 5.481568402408807e-07\n",
            "401 5.270329984367319e-07\n",
            "402 5.06723187636041e-07\n",
            "403 4.871960382424293e-07\n",
            "404 4.684213895220894e-07\n",
            "405 4.5037024301790184e-07\n",
            "406 4.33014717761703e-07\n",
            "407 4.16328007208233e-07\n",
            "408 4.002843378327513e-07\n",
            "409 3.848589293226123e-07\n",
            "410 3.7002795630127346e-07\n",
            "411 3.5576851152987916e-07\n",
            "412 3.4205857052566243e-07\n",
            "413 3.288769575438337e-07\n",
            "414 3.162033128703886e-07\n",
            "415 3.040180613761368e-07\n",
            "416 2.9230238228100927e-07\n",
            "417 2.8103818008466216e-07\n",
            "418 2.7020805661710233e-07\n",
            "419 2.5979528416658235e-07\n",
            "420 2.4978377964218444e-07\n",
            "421 2.4015807973288856e-07\n",
            "422 2.3090331702399554e-07\n",
            "423 2.2200519703291648e-07\n",
            "424 2.1344997613110857e-07\n",
            "425 2.0522444031625843e-07\n",
            "426 1.9731588480219806e-07\n",
            "427 1.897120943962158e-07\n",
            "428 1.8240132463183187e-07\n",
            "429 1.7537228362828715e-07\n",
            "430 1.6861411465060232e-07\n",
            "431 1.6211637934017274e-07\n",
            "432 1.5586904159212865e-07\n",
            "433 1.498624520541246e-07\n",
            "434 1.4408733322270431e-07\n",
            "435 1.3853476511318796e-07\n",
            "436 1.331961714828652e-07\n",
            "437 1.2806330658368513e-07\n",
            "438 1.2312824242717036e-07\n",
            "439 1.1838335653864165e-07\n",
            "440 1.1382132018416605e-07\n",
            "441 1.0943508705079577e-07\n",
            "442 1.0521788236287128e-07\n",
            "443 1.0116319241884456e-07\n",
            "444 9.726475452980349e-08\n",
            "445 9.351654734641305e-08\n",
            "446 8.991278155889296e-08\n",
            "447 8.64478909551478e-08\n",
            "448 8.311652382328898e-08\n",
            "449 7.991353468584456e-08\n",
            "450 7.683397635167653e-08\n",
            "451 7.387309227562576e-08\n",
            "452 7.102630921117364e-08\n",
            "453 6.828923014717936e-08\n",
            "454 6.565762751588525e-08\n",
            "455 6.312743666418616e-08\n",
            "456 6.06947495745769e-08\n",
            "457 5.835580882951291e-08\n",
            "458 5.6107001807907785e-08\n",
            "459 5.394485510481166e-08\n",
            "460 5.1866029167092425e-08\n",
            "461 4.986731313500184e-08\n",
            "462 4.7945619882884734e-08\n",
            "463 4.6097981250896086e-08\n",
            "464 4.432154346061449e-08\n",
            "465 4.2613562707360456e-08\n",
            "466 4.097140092171029e-08\n",
            "467 3.939252169562097e-08\n",
            "468 3.7874486364041686e-08\n",
            "469 3.6414950238919145e-08\n",
            "470 3.501165898714879e-08\n",
            "471 3.366244514904944e-08\n",
            "472 3.236522479040909e-08\n",
            "473 3.1117994283806455e-08\n",
            "474 2.991882721375856e-08\n",
            "475 2.8765871401598003e-08\n",
            "476 2.7657346044208938e-08\n",
            "477 2.6591538963808025e-08\n",
            "478 2.5566803963398962e-08\n",
            "479 2.4581558284015407e-08\n",
            "480 2.3634280160019428e-08\n",
            "481 2.2723506468796883e-08\n",
            "482 2.1847830470759422e-08\n",
            "483 2.100589963668148e-08\n",
            "484 2.0196413558541738e-08\n",
            "485 1.9418121941025346e-08\n",
            "486 1.8669822670309218e-08\n",
            "487 1.7950359957501043e-08\n",
            "488 1.7258622553235455e-08\n",
            "489 1.65935420314299e-08\n",
            "490 1.5954091138984373e-08\n",
            "491 1.5339282209192226e-08\n",
            "492 1.4748165636183706e-08\n",
            "493 1.4179828408244494e-08\n",
            "494 1.3633392697563574e-08\n",
            "495 1.3108014504384369e-08\n",
            "496 1.2602882353487569e-08\n",
            "497 1.2117216040820382e-08\n",
            "498 1.1650265428291116e-08\n",
            "499 1.1201309285195922e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMzDX7Qj5Q5T",
        "colab_type": "text"
      },
      "source": [
        "Fully connected "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krRvrLfM-LTy",
        "colab_type": "text"
      },
      "source": [
        "### Verify the Predictions \n",
        "- Obtained a predicted value from our model and compare to origional. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUWp2FU15Q5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "cbc6fb4c-a1df-4ddc-ed5f-53b2022ed8e5"
      },
      "source": [
        "pred = np.maximum(x.dot(w1),0).dot(w2)\n",
        "\n",
        "print (pred, \"\\n\", y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.        ]\n",
            " [0.99992661]\n",
            " [1.00007337]\n",
            " [0.        ]] \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWNhz_PI5Q52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "51d25a2e-4e00-4f52-9267-db7c9727b6ea"
      },
      "source": [
        "y\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMvnoVX55Q56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "69ec1a40-3e49-4f39-82e6-3d44b65a5f71"
      },
      "source": [
        "#We can see that the weights have been updated. \n",
        "w1"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20401151,  1.01377406],\n",
              "       [-0.10186284,  1.01392285],\n",
              "       [ 1.07856887,  0.01873049]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SIWdk6U5Q5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "445d580e-7613-4d43-c550-18ef4bb42c9b"
      },
      "source": [
        "\n",
        "w2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49346731],\n",
              "       [0.98634069]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAZjdYBF5Q6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "99a78c48-b073-44fb-a8bc-77c58270c6b4"
      },
      "source": [
        "# Relu just removes the negative numbers.  \n",
        "h_relu"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        ],\n",
              "       [0.        , 1.01377258],\n",
              "       [0.        , 1.01392433],\n",
              "       [0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ3UE4Cy5Q6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}